# activityClassifier
Data Collection and Preprocessing
Activity data was collected over multiple months using AndroSensor with a sampling rate of around 200Hz. After reviewing graphs (see Figures below) of the raw sensor data—sensors included all axes of both the gyroscope and accelerometer—I realized that arming and disarming the sensor resulted in significant amounts of noise at the ends of each clip, which was eliminated via trimming during preprocessing. The sampling rate of 200Hz was then down sampled to reduce the memory demands and noise of the original signal. I tried multiple sample rates under 100 Hz and found 50Hz to be a satisfactory compromise between resolution, run time, and performance. After down sampling, each activity session was split into second long intervals for feature extraction. Windowing the data in this manner enabled me to adopt a weighted majority approach for future activity sessions (discussed at the end of this overview). Finally, in my second month of data collection I realized that a significant portion of time was spent standing at stop lights. Instead of trying to remove standing sections from the data during preprocessing, I simply collected standing data and added it as a class.
   
Feature Engineering
To avoid overfitting and adding useless features which would bog down model speed/ performance in a production environment, I stuck with four features—mean, standard deviation, kurtosis, and skew—which were applied to each sensor component and two correlation measures—between accelX/accelZ and pitch/roll—that were inspired by a paper from Mannini and Sabatini . In addition to cutting down on computational overhead, minimizing feature count allowed for a more interpretable model, especially since the model uses basic classification algorithms as opposed to deep learning methods. 
After obtaining a feature vector for each window of data, I then applied PCA to reduce both noise and the chance of overfitting to imbalanced activity sessions. The features were also normalized using a ‘MaxAbsScaler’ that has been proven to work well in the past on similar time-series-based data sets.

Prediction and Design Decisions
A cursory look at the data set indicates that the activity classes are imbalanced. Stairs and squats sessions have many fewer samples than running and biking. I initially tried training my dataset without adjusting for this imbalance and achieved an accuracy of around 92% with every algorithm I tried. However, when I tested the saved models on different sessions, I realized that the system was simply predicting biking (the most populated class) every time. To adjust for this, I used Python’s imblearn library to over sample the minority classes with SMOTE (Synthetic Minority Oversampling Technique) in each successive K fold. Applying SMOTE after each K fold separation prevented the model from training on the synthetic aspect of the data and from predicting biking on each new session. 
After training on the oversampled data, RF, SVC, Gradient Boost, and KNeighbors classifiers obtained an accuracy of between 85% and 88%. I then saved these algorithms to be used in a majority voting system where a prediction is made on each window of data, with the class having the most votes being the predicted class. The system could have used an array of classes with associated confidence levels as an output, however, I opted against this approach as users do not want an activity tracker telling them what they might have done. Accuracy results and the majority voting algorithm can be found in the activityRecognition.py file of the accompanying directory.


